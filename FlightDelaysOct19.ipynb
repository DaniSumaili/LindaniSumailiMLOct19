{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries:\n",
    "import datetime, warnings, scipy \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime, warnings, scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#To show all columns on display output:\n",
    "pd.options.display.max_columns = 100\n",
    "#reading the file that contains the details of all flights:\n",
    "df = pd.read_csv('flights.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top rows view:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table dimensions:\n",
    "print('DataFrame dimensions:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attributes details:\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distinct values in Attributes:\n",
    "df.<Column name>.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infomation on columns types and number of missing/null values(Code from:):\n",
    "tab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})\n",
    "tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
    "tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()/df.shape[0]*100)\n",
    "                         .T.rename(index={0:'null values (%)'}))\n",
    "tab_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix:\n",
    "corrmat = df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining Year, Month and day  and make New Column Date: \n",
    "df['DATE'] = pd.to_datetime(df[['YEAR','MONTH', 'DAY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting variable to remove and keep:\n",
    "variables_to_remove = ['TAXI_OUT', 'TAXI_IN', 'WHEELS_ON', 'WHEELS_OFF', 'YEAR', \n",
    "                       'MONTH','DAY','DAY_OF_WEEK', 'AIR_SYSTEM_DELAY',\n",
    "                       'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
    "                       'WEATHER_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
    "                       'FLIGHT_NUMBER', 'TAIL_NUMBER', 'AIR_TIME']\n",
    "df.drop(variables_to_remove, axis = 1, inplace = True)\n",
    "df = df[['DATE','AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
    "        'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY',\n",
    "        'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY',\n",
    "        'SCHEDULED_TIME', 'ELAPSED_TIME','DISTANCE']]\n",
    "df[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking selected values missing values: \n",
    "missing_df = df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['filling factor (%)']=(df.shape[0]-missing_df['missing values'])/df.shape[0]*100\n",
    "missing_df.sort_values('filling factor (%)').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting train and testing datasets:\n",
    "df_train = df[df['DATE'].apply(lambda x:x.date()) < datetime.date(2015, 3, 31)]\n",
    "df_test  = df[df['DATE'].apply(lambda x:x.date()) > datetime.date(2015, 3, 31)]\n",
    "df = df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing Count, min, max, mean departure delay for all airlines: \n",
    "# function that extract statistical parameters from a grouby object:\n",
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(),\n",
    "            'count': group.count(), 'mean': group.mean()}\n",
    "#_______________________________________________________________\n",
    "# Creation of a dataframe with statitical infos on each airline:\n",
    "global_stats = df['DEPARTURE_DELAY'].groupby(df['AIRLINE']).apply(get_stats).unstack()\n",
    "global_stats = global_stats.sort_values('count')\n",
    "global_stats\n",
    "\n",
    "\n",
    "#Read the airlines datasets folder, then the full airline name in a dictonary:\n",
    "airlines= pd.read_csv('airlines.csv')\n",
    "airlines\n",
    "abbr_air = airlines.set_index('IATA_CODE')['AIRLINE'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing delays breakdown into categories\n",
    "# Function that define how delays are grouped 4 sections\n",
    "delay_type = lambda x:(((0,1)[x > 5],2)[x > 20],3)[x > 50]\n",
    "df['DELAY_LEVEL'] = df['DEPARTURE_DELAY'].apply(delay_type)\n",
    "#____________________________________________________\n",
    "fig = plt.figure(1, figsize=(10,7))\n",
    "ax = sns.countplot(y=\"AIRLINE\", hue='DELAY_LEVEL', data=df)\n",
    "#____________________________________________________________________________________\n",
    "# We replace the abbreviations by the full names of the companies and set the labels\n",
    "labels = [abbr_air[item.get_text()] for item in ax.get_yticklabels()]\n",
    "ax.set_yticklabels(labels)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=12, weight = 'normal', rotation = 0);\n",
    "plt.setp(ax.get_yticklabels(), fontsize=12, weight = 'bold', rotation = 0);\n",
    "ax.yaxis.label.set_visible(False)\n",
    "plt.xlabel('Flight count', fontsize=16, weight = 'bold', labelpad=10)\n",
    "#________________\n",
    "# Set the legend\n",
    "L = plt.legend()\n",
    "L.get_texts()[0].set_text('on time (t < 5 min)')\n",
    "L.get_texts()[1].set_text('small delay (5 < t < 20 min)')\n",
    "L.get_texts()[2].set_text('Medium delay (20 < t < 50 min)')\n",
    "L.get_texts()[3].set_text('Large delay (t > 50 min)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing train and test datasets(reducing from befor):\n",
    "df_train = df[df['DATE'].apply(lambda x:x.date()) < datetime.date(2015, 1, 10)]\n",
    "df_test  = df[df['DATE'].apply(lambda x:x.date()) > datetime.date(2015, 1, 10)]\n",
    "df = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting date and soring the new column\n",
    "df['DATE'] = pd.to_datetime(df[['YEAR','MONTH', 'DAY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating filling factor\n",
    "missing_df = df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['filling factor (%)']=(df.shape[0]-missing_df['missing values'])/df.shape[0]*100\n",
    "missing_df.sort_values('filling factor (%)').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with missing values\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract statistical parameters from a grouby object:\n",
    "def get_stats(group):\n",
    "    return {'count': group.count(),'max': group.max(),'min': group.min()\n",
    "            , 'mean': group.mean()}\n",
    "#_______________________________________________________________\n",
    "# Creation of a dataframe with statitical infos on each airline:\n",
    "global_stats = df['DEPARTURE_DELAY'].groupby(df['AIRLINE']).apply(get_stats).unstack()\n",
    "global_stats = global_stats.sort_values('count')\n",
    "global_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading airline file\n",
    "airlines= pd.read_csv('airlines.csv')\n",
    "airlines\n",
    "abbr_air = airlines.set_index('IATA_CODE')['AIRLINE'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all columns for tuning leaving only non-string and non-bool and non-date\n",
    "variables_to_remove = ['DATE','AIRLINE', 'ORIGIN_AIRPORT','DESTINATION_AIRPORT']\n",
    "df.drop(variables_to_remove, axis = 1, inplace = True)\n",
    "df = df[[ 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY',\n",
    "        'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY',\n",
    "        'SCHEDULED_TIME', 'ELAPSED_TIME','DISTANCE']]\n",
    "df[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training, tuning and testing \n",
    "\n",
    "# first class\n",
    "np.random.seed(50)\n",
    "train_data = np.random.normal(size=(100, 2))\n",
    "train_labels = np.zeros(100)\n",
    "\n",
    "# adding second class\n",
    "train_data = np.r_[train_data, np.random.normal(size=(100, 2), loc=2)]\n",
    "train_labels = np.r_[train_labels, np.ones(100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], c=train_labels, s=100, \n",
    "cmap='autumn', edgecolors='black', linewidth=1.5);\n",
    "plt.plot(range(-2,5), range(4,-3,-1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function that will return grid for further visualization.\n",
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, \n",
    "                                  random_state=17)\n",
    "\n",
    "# training the tree\n",
    "clf_tree.fit(train_data, train_labels)\n",
    "\n",
    "# some code to depict separating surface\n",
    "xx, yy = get_grid(train_data)\n",
    "predicted = clf_tree.predict(np.c_[xx.ravel(), \n",
    "                                   yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, predicted, cmap='autumn')\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], c=train_labels, s=100, \n",
    "            cmap='autumn', edgecolors='black', linewidth=1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "xx = np.linspace(0,1,50)\n",
    "plt.plot(xx, [2 * x * (1-x) for x in xx], label='gini')\n",
    "plt.plot(xx, [4 * x * (1-x) for x in xx], label='2*gini')\n",
    "plt.plot(xx, [-x * np.log2(x) - (1-x) * np.log2(1 - x)  for x in xx], label='entropy')\n",
    "plt.plot(xx, [1 - max(x, 1-x) for x in xx], label='missclass')\n",
    "plt.plot(xx, [2 - 2 * max(x, 1-x) for x in xx], label='2*missclass')\n",
    "plt.xlabel('p+')\n",
    "plt.ylabel('criterion')\n",
    "plt.title('Criteria of quality as a function of p+ (binary classification)')\n",
    "plt.legend();n_train = 150        \n",
    "n_test = 1000       \n",
    "noise = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = x.ravel()\n",
    "    return np.exp(-x ** 2) + 1.5 * np.exp(-(x - 2) ** 2)\n",
    "\n",
    "def generate(n_samples, noise):\n",
    "    X = np.random.rand(n_samples) * 10 - 5\n",
    "    X = np.sort(X).ravel()\n",
    "    y = np.exp(-X ** 2) + 1.5 * np.exp(-(X - 2) ** 2) + \\\n",
    "    np.random.normal(0.0, noise, n_samples)\n",
    "    X = X.reshape((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = generate(n_samples=n_train, noise=noise)\n",
    "X_test, y_test = generate(n_samples=n_test, noise=noise)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_tree = DecisionTreeRegressor(max_depth=5, random_state=17)\n",
    "\n",
    "reg_tree.fit(X_train, y_train)\n",
    "reg_tree_pred = reg_tree.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_test, f(X_test), \"b\")\n",
    "plt.scatter(X_train, y_train, c=\"b\", s=20)\n",
    "plt.plot(X_test, reg_tree_pred, \"g\", lw=2)\n",
    "plt.xlim([-5, 5])\n",
    "plt.title(\"Decision tree regressor, MSE = %.2f\" % (np.sum((y_test - reg_tree_pred) ** 2) / n_test))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['DEPARTURE_DELAY']\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=0.3,\n",
    "random_state=17)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, random_state=17)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for kNN, Scale features is required\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_holdout_scaled = scaler.transform(X_holdout)\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree.predict(X_holdout)\n",
    "accuracy_score(y_holdout, tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_holdout_scaled)\n",
    "accuracy_score(y_holdout, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_params = {'max_depth': range(1,11),\n",
    "               'max_features': range(1,10)}\n",
    "\n",
    "tree_grid = GridSearchCV(tree, tree_params,\n",
    "                         cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "tree_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_holdout, tree_grid.predict(X_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_jobs=-1))])\n",
    "\n",
    "knn_params = {'knn__n_neighbors': range(1, 10)}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_params,\n",
    "                        cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "knn_grid.best_params_, knn_grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_holdout, knn_grid.predict(X_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=20, n_jobs=-1, \n",
    "                                random_state=17)\n",
    "print(np.mean(cross_val_score(forest, X_train, y_train, cv=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {'max_depth': range(1,11),\n",
    "                 'max_features': range(1, 10)}\n",
    "\n",
    "forest_grid = GridSearchCV(forest, forest_params,\n",
    "                           cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "forest_grid.fit(X_train, y_train)\n",
    "\n",
    "forest_grid.best_params_, forest_grid.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_holdout, forest_grid.predict(X_holdout))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
